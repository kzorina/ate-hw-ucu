{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ConfigParser\n",
    "from my_suite_helpers.pdf_reader import read_to_clean\n",
    "from my_suite_helpers.utils import dataset_genreator, precision, recall, f_measure\n",
    "from my_suite_helpers.ATE_method import tf\n",
    "from my_suite_helpers.term_grouping import term_grouping, jaro_sim\n",
    "from my_suite_helpers.thd import thd\n",
    "import timeit\n",
    "import json\n",
    "import ate\n",
    "from os import listdir\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# GLOBAL\n",
    "pdf_folder = \"data/time\"\n",
    "txt_folder = \"data/txt\"\n",
    "clean_txt_folder = \"data/clean_txt\"\n",
    "golden_st_path = \"hands-on/D22.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_file_time = \"hands-on/time-onto-paper/MyTimeOnto-Paper-manually-extracted-terms.csv\"\n",
    "terms_gs_df_time = pd.DataFrame.from_csv(reference_file_time, sep=';')\n",
    "term_gs_agg_time= terms_gs_df_time.groupby(['term'])['num'].agg([np.sum])\n",
    "\n",
    "terms_gs_df = pd.DataFrame.from_csv(golden_st_path, sep=';')\n",
    "term_gs_agg = terms_gs_df.groupby(['term'])['num'].agg([np.sum])\n",
    "\n",
    "orders = ['chrono', 'rev-chrono', 'bi-dir', 'random']\n",
    "order = 'chrono'\n",
    "num_input = len([f for f in listdir(clean_txt_folder)])\n",
    "compare_to_c_value = True # c-value is very slow, so I disabled comparing\n",
    "\n",
    "config = ConfigParser.ConfigParser()\n",
    "config.readfp(open('config.ini'))\n",
    "min_term_length = int(config.get('main', 'min_term_length'))\n",
    "min_term_words = int(config.get('main', 'min_term_words'))\n",
    "stopwords = json.loads(config.get('main', 'stopwords'))\n",
    "term_patterns = json.loads(config.get('main', 'term_patterns'))\n",
    "\n",
    "term_extractor = ate.TermExtractor(stopwords=stopwords, term_patterns=term_patterns, min_term_words=min_term_words,\n",
    "                                   min_term_length=min_term_length)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1. Reading from PDF and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time = 541.463303506 s\n",
    "start = timeit.default_timer()\n",
    "read_to_clean(pdf_folder, clean_txt_folder)\n",
    "stop = timeit.default_timer()\n",
    "print(\"Elapsed time: {} s\".format(stop-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All results are saved to clean_txt folder.\n",
    "##### Elapsed time: 465 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2. Generating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = timeit.default_timer()\n",
    "dataset = dataset_genreator(order, num_input, clean_txt_folder)\n",
    "stop = timeit.default_timer()\n",
    "print(\"Elapsed time: {} s\".format(stop-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generator accepts 'chrono', 'rev-chrono', 'bi-dir', 'random' orders.\n",
    "##### Elapsed time: 4.08906234897 seconds for 424 docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3. ATE Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used tf for terms extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_to_c_value = False\n",
    "num_input = len([f for f in listdir(clean_txt_folder)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = term_extractor.extract_terms(dataset)\n",
    "print(\"Starting ATE on extracted terms...\")\n",
    "start_my_ate = timeit.default_timer()\n",
    "my_ate_terms_df = tf(terms)\n",
    "stop_my_ate = timeit.default_timer()\n",
    "print(\"Elapsed time for my ATE Method: {} s\".format(stop_my_ate - start_my_ate))\n",
    "if num_input == len([f for f in listdir(clean_txt_folder)]):\n",
    "    print(\"Metrics with golden standart from {}\".format(golden_st_path))\n",
    "    print(\"Precision = {}\".format(precision(my_ate_terms_df['term'].tolist(), term_gs_agg.index.values.tolist())))\n",
    "    print(\"Recall = {}\".format(recall(my_ate_terms_df['term'].tolist(), term_gs_agg.index.values.tolist())))\n",
    "    print(\"F measure = {}\".format(f_measure(my_ate_terms_df['term'].tolist(), term_gs_agg.index.values.tolist())))\n",
    "\n",
    "else:\n",
    "    print(\"Not enough documents to check precision with GS. \\n \")\n",
    "    # print(\"Precision = {}\".format(precision(my_ate_terms_df['term'].tolist(), term_gs_agg_time.index.values.tolist())))\n",
    "    # print(\"Recall = {}\".format(recall(my_ate_terms_df['term'].tolist(), term_gs_agg_time.index.values.tolist())))\n",
    "    # print(\"F measure = {}\".format(f_measure(my_ate_terms_df['term'].tolist(), term_gs_agg_time.index.values.tolist())))\n",
    "print(\"\")\n",
    "if compare_to_c_value:\n",
    "    print(\"Start measurements for comparison\")\n",
    "    start = timeit.default_timer()\n",
    "    c_value_terms = term_extractor.c_values(terms, trace=True)\n",
    "    stop = timeit.default_timer()\n",
    "    print(\"Elapsed time for reference c-value Method: {} s\".format(stop - start))\n",
    "    terms_cvalue_df = pd.DataFrame(c_value_terms)\n",
    "    if num_input == len([f for f in listdir(clean_txt_folder)]):\n",
    "\n",
    "        print(\"Metrics with golden standart from {}\".format(golden_st_path))\n",
    "        print(\"Precision = {}\".format(precision(terms_cvalue_df[0].tolist(), term_gs_agg.index.values.tolist())))\n",
    "        print(\"Recall = {}\".format(recall(terms_cvalue_df[0].tolist(), term_gs_agg.index.values.tolist())))\n",
    "        print(\"F measure = {}\".format(f_measure(terms_cvalue_df[0].tolist(), term_gs_agg.index.values.tolist())))\n",
    "    else:\n",
    "        print(\"Not enough documents to check precision with GS. \\n \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare on smaller file (as c-value is working too long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "fp = open(\"hands-on/time-onto-paper/TimeOnto-Paper.txt\", \"r\")\n",
    "doc_txt = fp.read() \n",
    "fp.close()\n",
    "doc_txt = unicode(doc_txt, \"utf-8\", errors='ignore')\n",
    "doc_txt = re.sub(r'et +al\\.', 'et al', doc_txt)\n",
    "doc_txt = re.split(r'[\\r\\n]', doc_txt)\n",
    "terms = term_extractor.extract_terms(doc_txt)\n",
    "golden_st_path = \"hands-on/time-onto-paper/MyTimeOnto-Paper-manually-extracted-terms.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting ATE on extracted terms...\")\n",
    "start_my_ate = timeit.default_timer()\n",
    "my_ate_terms_df = tf(terms)\n",
    "stop_my_ate = timeit.default_timer()\n",
    "print(\"Elapsed time for my ATE Method: {} s\".format(stop_my_ate - start_my_ate))\n",
    "\n",
    "print(\"Metrics with golden standart from {}\".format(golden_st_path))\n",
    "print(\"Precision = {}\".format(precision(my_ate_terms_df['term'].tolist(), term_gs_agg.index.values.tolist())))\n",
    "print(\"Recall = {}\".format(recall(my_ate_terms_df['term'].tolist(), term_gs_agg.index.values.tolist())))\n",
    "print(\"F measure = {}\".format(f_measure(my_ate_terms_df['term'].tolist(), term_gs_agg.index.values.tolist())))\n",
    "print(\"\")\n",
    "\n",
    "print(\"Start measurements for comparison\")\n",
    "start = timeit.default_timer()\n",
    "c_value_terms = term_extractor.c_values(terms, trace=True)\n",
    "stop = timeit.default_timer()\n",
    "print(\"Elapsed time for reference c-value Method: {} s\".format(stop - start))\n",
    "terms_cvalue_df = pd.DataFrame(c_value_terms)\n",
    "print(\"Metrics with golden standart from {}\".format(golden_st_path))\n",
    "print(\"Precision = {}\".format(precision(terms_cvalue_df[0].tolist(), term_gs_agg.index.values.tolist())))\n",
    "print(\"Recall = {}\".format(recall(terms_cvalue_df[0].tolist(), term_gs_agg.index.values.tolist())))\n",
    "print(\"F measure = {}\".format(f_measure(terms_cvalue_df[0].tolist(), term_gs_agg.index.values.tolist())))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results for my ATE\n",
    "Precision = 0.262355848435\n",
    "\n",
    "Recall = 0.00141646839074\n",
    "\n",
    "F measure = 0.00281772379229\n",
    "\n",
    "##### Elapsed time: 0.165914150476 s\n",
    "#### Results for reference implementation (C-value)\n",
    "Precision = 0.262355848435\n",
    "\n",
    "Recall = 0.00141646839074\n",
    "\n",
    "F measure = 0.00281772379229\n",
    "\n",
    "##### Elapsed time: 822.024772244 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 4. Term grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_genreator('random', 1, clean_txt_folder)\n",
    "terms = term_extractor.extract_terms(dataset, verbose=False)\n",
    "my_ate_terms_df = tf(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Term length before grouping = {}\".format(len(my_ate_terms_df)))\n",
    "start = timeit.default_timer()\n",
    "my_grouped_terms_df = term_grouping(my_ate_terms_df, 0.8)\n",
    "stop = timeit.default_timer()\n",
    "print(\"Term length after grouping = {}\".format(len(my_grouped_terms_df)))\n",
    "print(\"Elapsed time: {} s\".format(stop-start))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Term length before grouping = 803\n",
    "\n",
    "Term length after grouping = 520\n",
    "###### Elapsed time: 113.175545074 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 5. THD Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "for order in orders:\n",
    "    #for grouping in (True, False): # too long for grouoping\n",
    "    grouping = False\n",
    "    terms_list = []\n",
    "    thd_list = []\n",
    "    thdr_list = []\n",
    "    eps_list = []\n",
    "    for inc in range(1,21):\n",
    "        print(\"processing inc = {}, {} order, with grouping option {}\".format(inc,order, grouping))\n",
    "        dataset = dataset_genreator(order, inc, clean_txt_folder)\n",
    "        terms = term_extractor.extract_terms(dataset, verbose=False)\n",
    "        terms = tf(terms)\n",
    "        # if grouping:\n",
    "        #     terms = term_grouping(terms)\n",
    "        terms_list.append(terms)\n",
    "    for i in range(19):\n",
    "        print(\"thd, thdr measures for D{}-D{}\".format(i+1, i+2))\n",
    "        thd_value, thdr_value, eps = thd(terms_list[i], terms_list[i+1])\n",
    "        thd_list.append(thd_value)\n",
    "        thdr_list.append(thdr_value)\n",
    "        eps_list.append(eps)\n",
    "        print(\"Thd = {} and thdr = {}\".format(thd_value, thdr_value))\n",
    "    plot_thd_thdr(thd_list, thdr_list, eps_list, order)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print(\"Elapsed time: {} s\".format(stop-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_thd_thdr(thd, thdr, eps, title):\n",
    "    plt.plot(thd)\n",
    "    plt.plot(thdr)\n",
    "    plt.plot(eps)\n",
    "    plt.legend([\"thd\", \"thdr\", \"eps\"])\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_thd_thdr(thd_list, thdr_list, eps_list, order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 6. Taxonomy generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_file =\n",
    "start = timeit.default_timer()\n",
    "dataset = dataset_genreator(\"random\", 1, clean_txt_folder)\n",
    "terms = term_extractor.extract_terms(dataset)#, verbose=False)\n",
    "terms = tf(terms)\n",
    "\n",
    "threshold_match = 0.9\n",
    "threshold_combine = 0.6\n",
    "to_merge = {}\n",
    "to_combine = {}\n",
    "for k in range(len(terms)):\n",
    "    temp = terms.iloc[[k]][\"term\"]\n",
    "    temp2 = terms.iloc[[k]][\"term\"].tolist()[0]\n",
    "    term = str(terms.iloc[[k]][\"term\"].tolist()[0])\n",
    "    merge_list = []\n",
    "    combine_list = []\n",
    "    for j in range(k+1,len(terms)):\n",
    "        if jaro_sim(str(term), str(terms.iloc[[j]][\"term\"].tolist()[0])) > threshold_match:\n",
    "            merge_list.append(str(terms.iloc[[j]][\"term\"].tolist()[0]))\n",
    "            terms.drop(terms.index[j])\n",
    "        elif jaro_sim(str(term), str(terms.iloc[[j]][\"term\"].tolist()[0])) > threshold_combine:\n",
    "            combine_list.append(str(terms.iloc[[j]][\"term\"].tolist()[0]))\n",
    "    if len(merge_list)>0:\n",
    "        to_merge[term] = merge_list\n",
    "    if len(combine_list) > 0:\n",
    "        to_combine[term] = combine_list\n",
    "stop = timeit.default_timer()\n",
    "print(\"Elapsed time: {} s\".format(stop-start))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All results are saved to output.txt folder.\n",
    "##### Elapsed time: 174.118080098 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample output:\n",
    "###### Please think about merging next terms as they are pretty similar\n",
    "basic time units with ['basic time unit']\n",
    "\n",
    "time unit with ['time units']\n",
    "\n",
    "information systems with ['informatik systeme']\n",
    "\n",
    "overall workow execution with ['overall workow duration']\n",
    "\n",
    "\n",
    "###### Please think about combining somehow next terms\n",
    "process management with ['process reengineering purposes', 'time management tries', 'process priorities']\n",
    "\n",
    "time histogram with ['time violations', 'time problems', 'time property', 'time vi olations', 'time restrictions', 'time unit', 'time line', 'time model', 'time units', 'timely manner', 'timed graph', 'time interval', 'time value', 'time constraint violations', 'time management tries', 'time in workow systems', 'time management problems']\n",
    "\n",
    "latest allowed end blae with ['latest allowed start time']\n",
    "\n",
    "time interval with ['time value', 'valid time interval', 'time constraint violations', 'time management tries', 'time in workow systems', 'time management problems']\n",
    "\n",
    "green orange with ['cepe ', 'green everything']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
