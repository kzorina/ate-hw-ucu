2013 20th International Symposium on Temporal Representation and Reasoning  An algebraic system of temporal structures  Tim French John Mc Cabe-Dansted Mark Reynolds  School of Computer Science and Software Engineering, The University of Western Australia  35 Stirling Highway, Crawley WA 6009  Perth, Australia.  Abstract—Lauchli and Leonard, in 1966, described a series of  operations which are able to build all linear temporal structures  up to ﬁrst order equivalence. More recently these operations have  been used to describe executions of continuous systems for the  purposes of model checking real-time speciﬁcations. In this paper  we present an algebra over these operations and show that it is  both sound and complete, in that it can generate all equivalences  over these models.  [5] have increased the signiﬁcance of these problems. It is  useful to have a complete set of algebraic identities for model  expressions over general linear structures, but perhaps more  useful to have a set of such identities over dense continuous  structures, over the reals. However, we see in [2] that these  results come for free, as we can ﬁnd a syntactic restriction over  the set of all model expressions that guarantees the expression  corresponds to the reals. We aim to show that many other  common linear orders can also be identiﬁed with syntactic  restrictions of model expressions.  We anticipate that an algebraic approach for model expressions will be useful in the analysis of continuous systems.  Model expressions describing a trace of a continuous system  may be simpliﬁed, reduced to a canonical form, or proven  equivalent to another expression using this algebra.  I. I NTRODUCTION  Standard temporal logics are based on a discrete, natural  numbers model of time [1]. However, a dense, continuous  or speciﬁcally real-numbers model of time may be better  for many applications, ranging from philosophical, natural  language and AI modelling of human reasoning to computing  and engineering applications of concurrency, reﬁnement, open  systems, analogue devices and metric information.  One of the main results in the paper [2] was that a formula  of Real-Time Logic (RTL) has a real-ﬂowed model if has a  constructable real model. Here a real-ﬂowed model means a  model of linear temporal logic, whose underlying ﬂow of time  is represented by the real numbers, and a constructable real  model refers to a real model deﬁnable using a formal modelbuilding language based on the operations of Lauchli and  Leonard [3] (points, concatenation, leads, trails and shufﬂes,  also described in [4]).  In this paper we consider the generalization to arbitrary  linear temporal structures. The operations of Lauchli and  Leonard are able to generate expressions that correspond to  temporal structures in such a way that any satisﬁable formula  in the monadic second order theory of < is satisﬁed by such  a temporal structure. We refer to the generated expressions as  model expressions.  We will describe a number of known results for these model  expressions: most importantly,  1) every satisﬁable temporal logic formula is satisﬁed by  a temporal structure that corresponds to some model  expression; and  2) the class of temporal structures that correspond to a  given model expression is an isomorphism class.  That is, models expressions are able to ﬁnitely describe a satisfying structure for every satisﬁable temporal logic formula.  We will make this claim precise later. The main result of  this paper is to present an algebra over these operations that  is adequate for determining whether two model expressions  are equivalent. Model expressions are a natural artifact for  model-checking and synthesis problems over general linear  time, and recent applications of timed and hybrid automata  1530-1311/13 $26.00 © 2013 IEEE  1550-1311/13  DOI 10.1109/TIME.2013.18  II. L INEAR TEMPORAL S TRUCTURES  Fix a countable set L of atoms. Here, frames (T, <), or  ﬂows of time, will be irreﬂexive linear orders. Structures T =  (T, <, h) will have a frame (T, <) and a valuation h for the  atoms i.e. for each atom p ∈ L, h(p) ⊆ T .  An isomorphism is a bijective mapping from one structure  to another that preserves the temporal relation < and the  valuation h. This is an important notion of equivalence for  us, as we will show that equivalent structures satisfy the same  set of formulas in L(U, S).  DEFINITION 1: We say two structures T = (T, <, h) and  T  = (T  , < , h ) are isomorphic (written T ∼  = T  ) if and  only if there is a bijection f : T −→ T  where for all x, y ∈ T  x < y if and only if f (x) < f (y), and for all p ∈ P x ∈ h(p)  if and only if f (x) ∈ h (p). We say (T, <, h) and (T  , < , h )  are disjoint isomorphic if they are isomorphic and T and T   are disjoint.  To simplify notation below, given a structure (T, <, h), and    some T  ⊂ T , we let (T  , <, h) refer to the structure (T  , <T  T  T    , h ) where < is the restriction of < to the set T and    hT is the restriction of h to the domain T  . Isomorphisms  between structures preserve formulas of temporal logic just as  bisimulations preserves formulas of modal logic.  III. U NTIL AND S INCE OVER GENERAL LINEAR TIME  The language L(U, S, U  , S  ) is generated by the 2-place  connectives U and S along with classical ¬ and ∧ and the  Stavi connectives, U  and S  . That is, we deﬁne the set of  formulas recursively to contain the atoms and for formulas  α and β we include ¬α, α ∧ β, U (α, β), S(α, β), U  (α, β  71  81  and S  (α, β). For the detailed syntax and semantics of this  language, see [6].  This logic has been shown to be expressively complete  for monadic ﬁrst-order logic over arbitrary linear orders [6],  generalizing the result of Kamp for Dedekind complete linear  orders. This logic is decidable over arbitrary temporal structures and has been axiomatised [7].  ...  Fig. 1.  I1 I1  I1  I1  ←  −  The lead operation, where I = I1  For the inductive cases we require the notion of an isomorphism (Deﬁnition 1). Then:  IV. B UILDING S TRUCTURES  I + J corresponds to a structure (T, <, h) if and only  if T is the disjoint union of two sets U and V , where  ∀u ∈ U , ∀v ∈ V , v < u (we write U < V , from here  on) and I corresponds to (U, <, h) and J corresponds  to (V, <, h).  ←  −  • I corresponds to the structure (T, <, h) if and only if T  is the disjoint union of sets {Ui |i ∈ ω} where for all i,  Ui+1 < Ui , and I corresponds to (Ui , <, h).  →  −  • I corresponds to the structure (T, <, h) if and only if T  is the disjoint union of sets {Ui |i ∈ ω} where for all i,  Ui < Ui+1 , and I corresponds to (Ui , <, h).  • Γ corresponds to the structure (T, <, h) if and only if  T is the disjoint union of sets {Ui |i ∈ Q} where  1) for all i ∈ Q (Ui , <, h) corresponds to some γ ∈ Γ,  2) for every γ ∈ Γ, for every a = b ∈ Q, there is some  k ∈ (a, b) where γ corresponds to (Uk , <, h),  3) for every a < b ∈ Q, Ua < Ub .  PROPOSITION 1: Every  satisﬁable  formula  of  L(U, S, U  , S  ) is satisﬁed by a temporal structure that  corresponds to a model expression.  This is proven in [9]. It provides a strong motivation for investigating model expressions, as they are able to ﬁnitely represent temporal structures satisfying logical formulae, which  is important for such tasks as model-checking, synthesis and  counter-example generation [10].  We will give an illustration of the non-trivial operations  ←  −  below. The lead operation, I = I1 corresponds ω submodels,  each corresponding to I1 , and each preceding the last, as  illustrated in Figure 1.  The trail operator is the mirror image of the lead operation,  →  −  whereby I = I1 corresponds to ω structures, each corresponding to I1 and each proceeding the earlier structures.  The model expression I = Γ (I is the shufﬂe of Γ) corresponds to a dense, thorough mixture of intervals corresponding  to the elements of Γ, without endpoints. We deﬁne the shufﬂe  operation using the rationals, Q as they are a convenient linear  order to describe a dense, thorough mixing of intervals.  The deﬁnition of model expressions is not deterministic, as  the construct for the shufﬂe I1 , . . . , In does not specify how  the structures corresponding to I1 , . . . , In are mapped to the  rationals. We show that this inconsequential, and as long as  the mapping is dense for each i from 1 to n, the resulting  structures will be isomorphic.  LEMMA 1: Suppose that T = (T, <, h) and T  = (T  , <  , h ) both correspond to a model expression I. Then T and  T  are isomorphic.  Proof: We prove this by induction over the complexity of  model expressions. The base cases for letters and λ are trivial.  Model-checking and synthesis results require a description  of a ﬁnite model, whereas the natural representation of general  linear models is typically given over an inﬁnite (and often  uncountable) set of points. From [8] and [3], we know of a  set of operations that are able to generate sufﬁciently complex  structures for model-checking and synthesis purposes. These  are described in the following section.  Our main artifact of study in this paper is a notation which  allows us to describe temporal structures in sufﬁcient detail  to distinguish all concepts expressible in the monadic ﬁrstorder theory of <. These structures are deﬁned in terms of  simple basic structures via a small number of ways of putting  structures together to form larger ones.  The general idea is simple: using singleton structures (the  ﬂow of time is one point), we build up to more complex  structures by the recursive application of four operations. The  operations are:  • the concatenation of two structures, (placing one after the  other) consisting of one followed by the other;  • ω repeats of a given structure trailing off into the future;  • ω repeats of a given structure trailing back into the past  (or leading up to a point in the present)  • and making a densely thorough shufﬂe of copies from a  ﬁnite set of structures.  These operations are well-known from the study of linear  orders (see, for example, [8]).  We transform these operations into syntactic artefacts called  Linear Model Expressions, which are an abstract syntax for  deﬁning models. Suppose that Σ is some alphabet (in the  context of linear temporal logic, Σ would represent the set of  propositional atoms true at a point. Linear model expressions  are constructed using the follow set of primitive operators:  ←  − −  →  I ::= a | λ | I + J | I | I | Γ  •  where a ∈ Σ, for some alphabet Σ (in the context of linear  temporal logic, Σ would represent the set of atoms true at  a point), and Γ is a ﬁnite non-empty set of linear model  expressions. We refer to these operators, respectively, as a  letter, the empty order, concatenation, lead, trail, and shufﬂe.  Let E(Σ) be the set of all expressions generated over the  alphabet Σ.  DEFINITION 2 (Correspondence): Given Σ = 2L , a  model expression I corresponds to a structure as follows:  • λ is the empty sequence and corresponds to the frame  (∅, <, h) where < and h are empty relations.  • a corresponds to any single point model ({x}, <, h)  where < is the empty relation and h(p) = x if and only  if p ∈ a.  82  72  I≡d  d  ..  .  Fig. 2.  I  I  d  d  γ1  γ1  d  d  I  I  d  d  γ2  γ2  d. . . d  d. . . d  I  I  d  d  γn  γn  d  d  I  I    correspond to the same model  Q to Q where Ui and Uπ(i)  expression. By the induction hypothesis Ui and Uπ(i) must be  isomorphic, and thus the union of these isomorphisms will be  an isomorphism from T to T  .  LEMMA 2: Suppose that T = (T, <, h) and T  = (T  , <  , h ) are isomorphic. Then for any model expression I we have  T corresponds to I if and only if T  corresponds to I.  Proof: It is straightforward to see that the composition  of an isomorphism and a correspondence will be a correspondence.  From these lemmas, we have the following deﬁnition.  DEFINITION 3: We say two model expressions I1 and I2  are similar (written I1  I2 ) if and only if there is some  structure T = (T, <, h) such that both I1 and I2 correspond  to T .  Note that from Lemmas 2 and 1 it follows that similarity ()  is an equivalence relation over the set of model expressions.  Model expressions give us a grammar that describes linear  sequences in a similar manner to the way regular expressions  describe words over a given alphabet. However, there is an  important difference in that while regular expressions contain  non-deterministic operators (such as the Kleene star which  can match any number of repetitions, or disjunctions), the  interpretation of every operator in a model expression is  deterministic up to isomorphism (Lemma 1). Therefore, the  better analogue for a model expression is a single word over  a ﬁnite alphabet. In future work we will examine an analogue  of regular expressions for non-discrete time ﬂows, such as  a structure that admits general linear structures as traces.  However, it is important to provide a solid foundation for the  individual linear structures ﬁrst, which is the focus of this  paper.  We now focus on the question of equivalence for two model  expressions. Deﬁnition 3 provides a semantic notion of what it  means for two model expressions to represent the same information. The following section examines an algebraic approach  for demonstrating that two model expressions represent the  same information.  d  d  ..  .  The shufﬂe operation, where I = Γ, and Γ = {γ1 , γ2 , . . . , γn }.  For concatenation, suppose two structures T and T  correspond to the model expression I1 +I2 . Then T = (U ∪V, <, h)  where (U, <, h) corresponds to I1 , (V, <, h) corresponds to  I2 and every element of U is less than every element of V . We  also have T  = (U  ∪V  , < , h ) with similar constraints, so by  the induction hypothesis (U, <, h) is isomorphic to (U  , < , h )  and likewise (V, <, h) is isomorphic to (V  , < , h ). Taking the  union of these two isomorphisms we have an isomorphism  from T to T  as required.  For trail, suppose two structures T and T  correspond to the    →  −  model expression I2 . Then T = ( i∈ω Ui , <, h) where for all  i ∈ ω, (Ui , <, h) corresponds to I1 , and for all i ∈ ω, every  element of   Ui is less than every element of Ui+1 . We also  have T  = ( i∈ω Ui , < , h ) with similar constraints, so by the  induction hypothesis (Ui , <, h) is isomorphic to (Ui , < , h )  for every i ∈ ω. Taking the union of these isomorphisms we  have an isomorphism from T to T  as required.  The case for lead is similar so that leaves shufﬂes. Suppose  two structures T and T  correspond to the   model expression  Γ . From Deﬁnition 2 we have T = ( i∈Q Ui , <, h), and    T = ( i∈Q Ui , < , h ) where the Ui and Ui are disjoint,  and correspond to the model expressions γ ∈ Γ. As the  correspondence between the Ui and the model expressions  is dense, we can build a 1-1 mapping π ⊂ Q × Q by a  transﬁnite induction: we enumerate Q and process them in  order to deﬁne the mappings πx for x ∈ ω. Suppose that i  is the xth element of the enumeration and Ui corresponds to  γ ∈ Γ. If i is not already paired with any element in πx−1 ,  we let j be the least element greater than i where j is in the  domain of πx−1 , and the let k be the greatest element less than  i that appears in the domain of πx−1 . Then select some  where  πx−1 (k) <  < πx−1 (j), and where U corresponds to γ. If no  such j or k exists, we may ignore the corresponding constraint,  and we can always ﬁnd such an  because the shufﬂe is dense).  We can then repeat the process to ﬁnd some  so that U is an  isomorphic match for Ui , and add both pairs, (i, ) and ( , i),  to the mapping to deﬁne πx . Note that the mapping is designed  so that it is order-preserving (i.e. pix (i) < πx (j) only if i < j.  The limit step takes the union of all interim mappings and  will deﬁne a total one-to-one order-preserving mapping from  V. A N ALGEBRA FOR MODEL EXPRESSIONS  In this section we present an algebra for model expressions. The algebra is presented as a series of identities or  equivalences with the intent that any two equivalent model  expressions are isomorphic to exactly the same set of temporal  structures. We write I ≡ J to indicate that two model  expressions, I and J are equivalent in the algebraic sense.  DEFINITION 4: The model expression algebra is as follows.  Associativity  1.  I1 + (I2 + I3 ) ≡ (I1 + I2 ) + I3  The shufﬂe identities  −−−−−→  2. Θ + θ ≡ Θ where θ ∈ Θ  ←−−−−−  3. θ + Θ ≡ Θ where θ ∈ Θ  4. Θ + θ + Θ ≡ Θ where θ ∈ Θ  5. Γ ∪ {θ + Θ + θ } ≡ Θ where Γ ⊂ Θ, θ, θ ∈ Θ  83  73  The lead/trail identities  −−−−→  −−−−→  6. I1 + I2 ≡ I1 + I2 + I1  −−−−−−−→ −  →  7. I + . . . + I ≡ I  ←−−−− ←−−−−  8. I1 + I2 ≡ I2 + I1 + I2  ←−−−−−−− ←  −  9. I + . . . + I ≡ I  The λ identities  10.  11.  12.  13.  14.  15.  I +λ≡I  λ+I ≡I  →  −  λ ≡λ  ←  −  λ ≡λ  λ ≡λ  Θ ≡ Θ ∪ {λ}  The substitution rule  If I ≡ J then K ≡ K[I\J ]  where K[I\J ] is the expression K with all occurrences of the  subexpression I replaced with the expression J .  We note that this algebra is actually a schema due to  identities (2-5, 7 and 9) which apply to a qualiﬁed set of  terms. The identities (2-5) also refer to set operations which  can further complicate derivations. For example, we can show  {I, I + λ} is equivalent to {I} for any model expression  I, by applying equivalence (10) to note that I + λ ≡ I, and  then applying the substitution rule to show {I, I + λ} is  equivalent to {I, I} . At this point we note that {I, I} is  simply the set {I}, but this ﬁnal step is in some sense external  to our system as it appeals to the deﬁnition of a set.  EXAMPLE 1: For an example of a more complex identity,  suppose that a ∈ Σ is some letter and consider the equivalence  ←−−−−−−−−−−−−  a + {a + a} + a ≡ {a + a} + a. We can see that such an  identity makes sense semantically. On the right side we have  a dense mix of {a + a} followed by a single point a. On the  left we have an ω-sequence leading to the left of the point a,  followed a dense mix of a + a, followed by a point a. When  we lay this ω-sequence out we ﬁnd the pattern:  . . . + a + {a + a} + a + a + {a + a} + a + a + {a + a} + a.  Now, each instance of {a+a} +a+a+ {a+a} is equivalent  to {a + a} , so the whole structure collapses down to {a +  a} +a, and hence the expressions are semantically equivalent.  With respect to the algebra, we have the derivation:  ←−−−−−−−−−−−−  ←−−−−−−−−−−−−  a + {a + a} + a ≡ a + a + {a + a} + a  (8)  ≡ {a + a} + a  (3)  VI. S OUNDNESS  We must ﬁrst convince ourselves that the model expression  algebra will only generate valid equivalences.  LEMMA 3 (Soundness): Suppose that I1 and I2 are model  expressions such that I1 ≡ I2 . Then I1  I2  Proof: (Sketch)  It is sufﬁcient to show that all rules preserve equivalence with  respect to the correspondence relation, so that is I corresponds  to T and I ≡ J is an identity of the model expression algebra,  then J also corresponds to T . As equivalence (≡) is simply  deﬁned as the result of the iterated application of these rules, it  follows that equivalence preserves the correspondence relation.  Showing that each rule preserves the correspondence relation  is straightforward and we present brief arguments for some of  the equivalences below:  1 I1 + (I2 + I3 ) ≡ (I1 + I2 ) + I3 : the concatenation  operator is clearly associative.  −−−−−→  2 Θ + θ ≡ Θ where θ ∈ Θ: an ω-sequence of  shufﬂes is isomorphic to a shufﬂe.  4 Θ +θ + Θ ≡ Θ where θ ∈ Θ: this is the essential  deﬁnition of a shufﬂe operator.  5 Γ∪{θ+ Θ +θ } ≡ Θ where Γ ⊂ Θ and θ, θ ∈ Θ:  if Γ is a subset of Θ then Γ ∪ { Θ } is a dense mix  of elements from Γ and Θ . However, as elements of  Γ already appear densely in Θ , so nothing is gained  from having them appear independently of the elements  in Θ. Likewise, within a shufﬂe, there is effectively  no difference between a closed interval and an open  interval, so the addition of θ, θ at the ends of Θ are  negligible.  −−−−→  −−−−→  6 I1 + I2 ≡ I1 + I2 + I1 : an ω-sequence alternating  between I1 and I2 is the same as an ω alternating  between I2 and I1 , with I1 appended to the front.  −−−−−−−→  →  −  7 I + . . . + I ≡ I : an ω-sequence of a ﬁnite homogeneous sequence of I is just an ω-sequence of I.  10-15 These rules capture how the empty sequence λ acts as  a kind of identity for all operators.  Finally we note that the substitution rule must be sound  since any substructure that I corresponds to must also be a  substructure that J corresponds to, so the correspondence of  K to a structure will not be affected by the substitution.  VII. C OMPLETENESS  Completeness requires us to show that any two expressions  that correspond to a common temporal structure, are provably  equivalent using the model expression algebra.  LEMMA 4 (Completeness): Suppose that I and J are  model expressions such that I  J . Then I ≡ J .  This is the more complicated lemma to prove and will rely  on a sequence of deﬁnitions and sub-lemmas. We will give  these below and bring them together in the proof of Theorem 1.  Our proof uses a two player game G(I, J ) derived from the  two model expressions I and J . The game is such that player  Felix (the Duplicator) has a winning strategy if and only  if I  J , and otherwise player Ralph (the Spoiler) has a  winning strategy. Then, from Felix ’s winning strategy (and  EXAMPLE 2: A useful derivation to have is the ﬁxed-point  ←  −  deﬁnition of a lead: I + I ≡ I. We can show this with the  following derivations:  ←−−−  ←  −  I ≡ λ+I  (11) and substitution  ←−−−  ≡ I +λ+I  (8)  ←  −  ≡ I +I  (10) and substitution.  In the next few sections we will show that the algebra is  sound (so that I1 ≡ I2 only if I1  I2 ) and complete (so that  I1 ≡ I2 if I1  I2 ).  84  74  Sketch: If I  J then both expressions correspond to  a common linear structure, T = (T, <, h). We will use this  correspondence to guide a winning strategy for Felix in the  game. We will proceed by induction and we will suppose  that we have game states (I i , J i ) where both I i and J i  correspond to a structure T i . The base of our induction is  I 0 = I, J 0 = J and T 0 = T . Now suppose that given a state  (I i , J i ), Ralph plays a move I i ≡ I1 +I2 . From Lemma 3 we  must have that I1 + I2 also corresponds to T i = (T i , <i , hi ).  Applying Deﬁnition 2 this means that T i is the disjoint union  of two sets U and V where V < U and I1 corresponds  to (U, <, h) and I2 corresponds to (V, <, h). As J i also  corresponds to T i we need to ﬁnd a derivation J i ≡ J1 + J2  where J1 corresponds to (U, <, h) and J2 corresponds to  (V, <, h). We can then show that as long as Felix continues  to produce such derivations, then Ralph can never reach  a winning state. We will provide an inductive argument to  show the Felix can always ﬁnd a suitable derivation (and the  previous two cases form the basis of this induction). The claim  is that given an expression K that corresponds to a structure,  T = (T, <, h), and a partition of that structure into two sets  U and V where V < U , we can always ﬁnd a derivation  K ≡ K1 + K2 such that K1 corresponds to (U, <, h) and  K2 corresponds to (V, <, h). We proceed by induction over  the complexity of formulas, where the ﬁrst two cases are the  basis, and the inductive steps follow:  Ralph’s lack of a winning strategy) we are able to extract a  series of equivalences showing I ≡ J .  DEFINITION 5: Given two model expressions I and J we  deﬁne G(I, J ) to be the equivalence game of I and J , where:  1) The game is played between two players, Felix and  Ralph.  2) At any time, the state of game is a pair (I  , J  ) where  I  and J  are model expressions, and the game starts at  the state (I, J ).  3) Given the state (I  , J  ), the next step of the game  proceeds as follows:  a) Ralph performs a sequence of ≡ transformations  to I  manipulating it into an expression I1 + I2  b) Felix performs a sequence of ≡ transformations to  J  manipulating it into an expression J1 + J2  c) Ralph then selects the next state of the game to be  either (I1 , J1 ) (the left), (J1 , I1 ) (the left switch),  (I2 , J2 ) (the right), or (J2 , I2 ) (the right switch).  4) Ralph wins the game if it reaches a state  a) (λ, I) where I = λ,  b) (a, I) where a is an atom and I = a,  Otherwise Felix wins.  Note that the game is not necessarily ﬁnite, but the only way  Ralph can win is to force the game into a ﬁnal state in a ﬁnite  number of moves.  LEMMA 5: For all model expressions I and J , the game  G(I, J ) is determined. That is, either Ralph or Felix has a  winning strategy.  Proof: This follows from the fact that there are only a  countable number of winning plays for Ralph, and they are all  ﬁnite. Therefore, an inductive construction of Ralph’s winning  set has a well-deﬁned limit.  EXAMPLE 3: For an example of the game, consider Example 1. Here it is clear that Felix has a winning strategy.  ←−−−−−−−−−−−−  Let I = a + {a + a} + a and J = {a + a} + a. From  the game state (I, J ), Ralph will move ﬁrst and produce a  derivation I ≡ I + I  . Felix ’s winning strategy is simply  to ﬁrst repeat the derivation in Example 1 and compose this  derivation with which ever derivation Ralph produced, so we  have J ≡ I + I  . From then he can mimic exactly every  move Ralph makes. Ralph could reach states (a, a) or (λ, λ)  but neither of these states are winning, so the game continues  indeﬁnitely (because the λ-identities always ensure another  move is available).  For a game in which Ralph has a winning strategy, suppose  that I is deﬁned as above, but J = {a + a} . In this case  Ralph could choose the derivation I ≡ {a + a} + a that  appeared in Example 1. Whatever derivation J = J  + J   Felix tries, he will always ﬁnd that J  contains a dense mix  of {a + a} or λ and is deﬁnitely not equal to a. So Ralph  wins the game by choosing the right.  We will show that a winning strategy for Felix in the game  G(M1 , M2 ) is equivalent to both M1  M2 and M1 ≡ M2 .  We ﬁrst prove the following sub-lemma, by induction over  the complexity of formulas.  LEMMA 6: Felix has a winning strategy in the game  G(I, J ) if and only if I  J .  •  •  •  •  85  75  If K = λ, then T = ∅ and thus U and V are also the  empty set. Felix can produce the derivation K ≡ λ + λ  using (11).  If K = a, where a ∈ Σ, then it must be the T is a single  point, x, where hi (x) = a. As I1i + I2i corresponds to  T we must have either U = {x} and V = ∅ for U = ∅  and V = {x}. In the ﬁrst case Felix can produce the  derivation K = a + λ (11) and in the second case Felix  can produce the derivation K = λ + a (12).  If K = K1 + K2 then T i is the disjoint union of two  sets U  and V  where for all u ∈ U  , for all v ∈ V  ,  u < v. Suppose without loss of generality V  ⊂ V . Let  V ∗ = V ∩ U  . Then K1 corresponds to (U ∪ V ∗ , <, h)  where everything in U is less than everything in V ∗ . Applying the induction hypothesis K1 ≡ K3 +K4 where K2  corresponds to U and K4 corresponds to V ∗ . Applying  the substitution rule we have K ≡ (K3 +K4 )+K2 and by  (1), we can complete the derivation K ≡ K3 + (K4 + K5 )  where K3 corresponds to U and K4 + K5 corresponds to  V.  ←  −  If K = K1 then by Deﬁnition 2, T is the disjoint union  of sets {Ui |i ∈ ω} where for all i, for all u ∈ Ui , for all  v ∈ Ui+1 , v < u, and K1 corresponds to (Ui , <, h). As  T is totally   ordered by < there is some greatest j ∈ ω  such that i<j Ui ⊆ V . We can apply the derivation of  ←  −  Example 2 j times so that K ≡ K1 + jK1 . Let U ∗ =  ∗  U ∩ Uj , V = V ∩ Uj . Then K1 corresponds to (U ∗ ∪  V ∗ , <, h) where everything in U ∗ is less than everything  in V ∗ . Applying the inductive hypothesis we have K1 ≡  K2 +K3 where K2 corresponds to U ∗ and K3 corresponds  to V ∗ . Using the substitution rule and (1), we can show  ←  −  ←  −  that K ≡ K1 + K2 + K3 + (j − 1).K1 where K1 + K2  corresponds to U and K3 + (j − 1).K1 corresponds to V .  −  →  ←  −  • The case for K = K1 is the symmetric case to K = K1 .  • If K = Γ where Γ = {I1 , . . . , In } then T is the disjoint  union of sets {Ui |i ∈ Q} satisfying the conditions laid  out in Deﬁnition 2. Let i be the element of Q such that  Ui ⊂ U and Ui ⊂ V , if it exists (i.e. Ui is the substructure  that crosses from one partition into the other). If such an  element doesn’t exist, then every Ui is either entirely in  U or entirely in V and there are three cases to consider.  1) If there is a least Ui ⊂ V (with respect to <) such  that Ij corresponds to Ui , we have by (4), K ≡  Γ + Ij + Γ , where Γ corresponds to U and  Ij + Γ corresponds to V .  2) If there is a greatest Ui ⊂ U such that Ij corresponds to Ui , we have by (4), K ≡ Γ + Ij + Γ ,  where Γ + Ij corresponds to U and Γ corresponds to V .  3) If there is neither a greatest Ui ⊂ U , nor a least  Ui ⊂ V , then by (15) K ≡ Γ ∪ {λ} and by (4)  and (15) K ≡ Γ + λ + Γ and ﬁnally by (12)  K ≡ Γ + Γ where Γ corresponds to both U  and V .  Otherwise there is an element i ∈ Q such that Ui ⊂ U  and Ui ⊂ V . Let U ∗ = U ∩Ui , V ∗ = V ∩Ui and suppose  that Ij corresponds to Ui . By the induction hypothesis we  have Ij ≡ K1 + K2 where K1 corresponds to U ∗ and K2  corresponds to V ∗ . By (14) K ≡ Γ + Ij + Γ , and  applying the substitution rule we have K ≡ Γ + K1 +  K2 + Γ where Γ + K1 corresponds to U and K2 + Γ  corresponds to V .  Therefore, what ever choice Ralph makes, Felix can always  respond ﬁnding a pair J1 , J2 corresponding to the respective  partition of T . The induction shows that Ralph will never be  able to reach a winning state, so it must be a winning strategy  for Felix .  Conversely, if Felix has a winning strategy in the game, we  can show that the two expressions correspond to isomorphic  structures by building a model extracted from all plays of the  game according to Felix ’s winning strategy.  We deﬁne a non-deterministic strategy for Ralph. Since  Felix has a winning strategy, Felix can win every game against  this strategy. However, this strategy is deﬁned so that every  play that reaches an atomic state ((a, a), since it is a winning  state for Felix ), and this corresponds to a unique point in a  linear structure T . We will show the structure T corresponds  to both I and J as required.  The strategy for Ralph, σ maps game states (I, J ) to a  derivation for I, σ(I) = I  + I  where I ≡ I  + I  . When  I  + I  is played, Player Felix will respond by applying the  winning strategy to select a derivation J = J  + J  . Then  Ralph non-deterministically selects the left (I  , J  ) or the  right (I  , J  ). The function σ is deﬁned inductively over the  complexity of expressions:  σ(λ) = λ + λ  σ(K + K ) = K + K  →  −  →  −  σ( K ) = K + K  In the last clause γ is non-deterministically chosen from Γ ∪  {λ}.  We consider all plays that may result from this nondeterministic strategy for Ralph against Felix ’s winning strategy. Let ΠIJ be the set of ﬁnite plays of game, π = π0 π1 . . . πn  where π0 = (I, J ) and πn = (a, a) for some a ∈ Σ. We  deﬁne an ordering over ΠIJ by π < τ if and only if, for the  largest j where for all i < j, πi = τi , we have πj is a left  move and τj is a right move. Finally, we deﬁne the function  I  h : L → 2ΠJ , by π ∈ h(a) if and only if πn = (a, a). Note  that there are also plays winning for Felix that end in the  state (λ, λ), but these may be ignored as they correspond to  the empty ﬂow of time, and do not affect the ﬁnal structure.  We can then show that (ΠIJ , <, h) corresponds to both I  and J , by induction over the complexity of I. The induction  hypothesis is that for all sub-expressions I  of I, for all J  ,  if Felix has a winning strategy in the game G(I  , J  ) then    (ΠIJ  , <, h) corresponds to both I  and J  . The base case  of I = J = a is obvious. The operators concatenation,  lead, trail and shufﬂe are simple applications of the recursive  deﬁnition of correspondence, given the soundness of the model  expression algebra (Lemma 3). Therefore I  J as required.  The ﬁnal part of the completeness proof will require us to  show that Felix has a winning strategy in the game G(I, J ) if  and only if I ≡ J . The proof will proceed via induction over  the complexity of model expressions, where the complexity of  a model expression is given by the following deﬁnition.  DEFINITION 6: Model Expression Complexity We say  one expression I is an equivalent subexpression of another  J (written I  J ) if there exists expressions K and K such  that K + I + K ≡ J .  The complexity of a model expression I, is a map  c : E(Σ) −→ ω × ω deﬁned inductively over the formulaic  complexity of model expressions as follows:  • Atoms  – c(λ) = (0, 0)  – c(a) = (0, 1)  • Concatenation  – c(I + I  ) = max(c(I), c(I  )).  • Lead/Trail  ←  −  ←  −  – If c(I) = (a, b) and I  I, c( I ) = (a, b).  ←  −  ←  −  – If c(I) = (a, b) and I  I, c( I ) = (a, b + 1).  →  −  →  −  – If c(I) = (a, b) and I  I, c( I ) = (a, b).  →  −  →  −  – If c(I) = (a, b) and I  I, c( I ) = (a, b + 1).  • Shufﬂe  – If for every γ ∈ Γ we have Γ  γ, then c( Γ ) =  max{c(γ) | γ ∈ Γ}.  – Otherwise if max{c(γ) | γ ∈ Γ} = (a, b) then  c( Γ ) = (a + 1, 0).  We note that over ω × ω, max is determined with respect to  the lexicographical relation, so that (a, b) < (c, d) if and only  if a < c or a = c and b < d.  This complexity orders expressions in two dimensions.  Essentially every nesting of a lead or a trail increases the  complexity by one in the second dimension, and every nesting  σ(a) = undeﬁned  ←  −  ←  −  σ( K ) = K + K  σ( Γ ) = ( Γ + γ) + Γ  86  76  some b > 0. Applying the same process from the previous  case, for arbitrary n we may show that J ≡ Jn +. . .+J0  where for all i < n, Ji corresponds to (Ui , <, h). The  only operations that can generate such a sequence are  shufﬂe or lead, and as a shufﬂe has been ruled out we  ←  −  must have J ≡ J  for some J  that corresponds to  (U0 , <, h). By the inductive hypothesis c(I  ) = (a, b) =  c(J  ) for some (a, b) and hence c(I) = c(J ) = (a, b +  1).  →  −  • Suppose that I = I and I  J . This case is simply the  mirror image of the previous case.  • Suppose that I = Γ and I  J . We can ﬁnd a partition  of T , {Ui |i ∈ Q} such that for each a < b ∈ Q, Ua < Ub ,  and for each γ ∈ Γ there is some c where a < c < b,  and γ corresponds to (Uc , <, h). Again, the processes  of Lemma 6 can be applied to show that J must be  equivalent to some shufﬂe Θ , where for every a < b ∈  Q, for every θ ∈ Θ, there is some c where a < c < b and  θ corresponds to (Uc , <, h). By the induction hypothesis  for every γ ∈ Γ there must be some θ ∈ Θ such that  c(γ) = c(θ) and vice versa. Therefore, we must have  c(I) = c(J ).  By induction over the syntax of expressions the Lemma must  hold.  We note that as a corollary of Lemmas 6 and 8, if two  expressions I and J have different model expression complexity, then Ralph must have a winning strategy in the game  G(I, J ).  LEMMA 9: Felix has a winning strategy in the game  G(I, J ) if and only if I ≡ J .  Proof: If I ≡ J then Felix has a clear winning strategy:  his ﬁrst move is to perform the deductive steps to transform J  into I and append any deductions the Ralph made in his ﬁrst  move. From then on he simply mirrors every one of Ralph’s  moves, guaranteeing a winning strategy.  of a shufﬂe increase the dimension by one in the ﬁrst dimension and resets the second dimension to zero. Therefore every  expression with a shufﬂe as the outermost operator will always  have complexity (a, 0). There are a few cases where leads,  trails and shufﬂes of expressions don’t substantially change  the expression (see the shufﬂe identities in Deﬁnition 4), and  in these case the complexity is left at (a, 0).  Some examples of model expression complexities are:  −  c(←  a ) = (0, 2)  (1)  c( {a} ) = (1, 0)  ←−−−  c(a + {a} ) = (1, 0)  ←−−−−−−  c(a + {a} ) = (1, 0)  ←−−−−−−  c(b + {a} ) = (1, 1)  (2)  (3)  (4)  (5)  These formulas give some idea of how the complexities  build. Each shufﬂe acts as a type of limit for the inductive  application of lead and trails. We see in the formula (3) and  (4) the complexity does not increase with the application of  concatenation or lead operations, as these are “absorbed” by  the underlying shufﬂe (in fact we can see that the formula in  (4) is equivalent to the formula in (2). However, for (5) we  see the complexity does increase because the sub-expression  b cannot be absorbed by the shufﬂe (since the ﬁrst clause for  ←−−−−−−  the lead complexity does not hold: b + {a}  b + {a} ).  In this case we say the subexpression b is an impurity in the  expression b + {a} .  LEMMA 7: If I ≡ J then c(I) = c(J ).  Proof: The result follows clearly from inspection of  Deﬁnition 4. As the model expression complexity of the left  and right side of each equivalence are clearly equal, it follows  by a simple inductive argument that equivalent expressions  must have the same model expression complexity.  LEMMA 8: If I  J then c(I) = c(J ).  Proof: We give this proof by induction over the syntax  of expressions. The base cases of λ and atoms, a ∈ Σ are  straight forward: if a  J then J can only be an expression  K + a + K where K and K are expressions built only from  λ, and as such both expressions must have complexity (0, 1).  The case for λ is also trivial.  For the inductive steps we consider the model expression I,  and suppose that both I and J correspond to some structure  T = (T, <, h).      • Suppose I = I + I  and I  J . Therefore J  also corresponds to T and there are subsets U1 < U2  of T such that I  corresponds to (U1 , <, h) and I   corresponds to (U2 , <, h). From Lemma 6, we know that  J ≡ J  + J  , where J  corresponds to (U1 , <, h)  and J  corresponds to (U2 , <, h). By the induction  hypothesis, c(I  ) = c(J  ) and c(I  ) = c(J  ) so the  result follows from←  −Deﬁnition 6.  • Suppose that I = I and I  J . Therefore there is some  partition {Ui |i ∈ ω, Ui+1 < Ui } of T such that for every  i ∈ ω, I  corresponds to Ui . There are two sub-cases to  consider. If each I also corresponds to each Ui , then  c(I) = (a, 0) for some a, and the case may be treated as  a shufﬂe below. Otherwise we will have c(I) = (a, b) for  For the converse, if Felix has a winning strategy in the game  G(I, J ) each move of Felix is going to involve a derivation.  We can use this winning strategy to construct a complete  derivation of the equivalence I ≡ J , proceeding by induction  over the complexity of formulas as deﬁned in the Deﬁnition 6.  The induction hypothesis is that Felix has a winning strategy  in the game G(I  , J  ), for all I  with a model expression  complexity less than c(I), and also for all I  which are strict  subexpressions of I.  The base of this induction will be expressions of complexity  less than or equal to (0, 1).  • If c(I) = (0, 0) then it is clear from Deﬁnition 6 that I ≡  λ. Therefore if Felix has a winning strategy in the game  G(I, J ) then it must be the case that J ≡ λ, otherwise  Ralph would have a winning move of I ≡ λ + λ.  • If c(I) = (0, 1) then from Deﬁnition 6 it follows that  I is equivalent to a concatenation of atoms and λ (as  any instance of lead, trail or shufﬂe applied to an atom  would increase the complexity beyond (0, 1). If Felix has  a winning strategy in the game G(I, J ) it must follow  that for every decomposition I ≡ I  + I  , Felix can  ﬁnd some decomposition J ≡ J  + J  such that Felix  87  77  as c(J ) must be 0 in its second element, and any subexpression that cannot be reduced by the shufﬂe identities  (Deﬁnition 4.2-5) can easily be exploited by Ralph to  give a winning strategy. Ralph can, for i = 1 . . . m, play  the derivation I ≡ I + Ii + I. The winning strategy of  Felix must be able to respond with J ≡ J + K + K +  K + J where Felix has a winning strategy in the game  G(Ii , K) and K + K + K ≡ Jj for some j. By the  induction hypothesis we have Ii ≡ K, and furthermore,  I  K , K . A similar equivalence may be given for Ji  for i = 1 . . . n, so the result follows by the substitution  rule and the ﬁrst shufﬂe identity (Deﬁnition 4.5).  Therefore the induction holds and we are able to construct  a full derivation of the equivalence between I and J from  Felix ’s winning strategy in the game G(I, J ).  THEOREM 1: Given any two model expressions I and J  we have I  J if and only if I ≡ J .  Proof: The right to left direction (I ≡ J implies I  J )  is simply Lemma 3. The opposite direction (I  J implies  I ≡ J ) corresponds to Lemma 4 which follows directly from  Lemmas 6 and 9. Therefore the model expression algebra  (Deﬁnition 4) is sound and complete.  has a winning strategy in the left, right, left switch and  right switch states. The result follows by induction over  the complexity of expressions (the standard deﬁnition, as  opposed to the model expression complexity). The base  of this induction has I and J as the same atom (since  Ralph cannot win) and for the inductive step we may  assume that I  ≡ J  and I  ≡ J  , so the result follows  immediately.  There are now a number of different inductive cases to  consider:      • I = I + I In this case it is clear that as Felix has  a winning strategy, if Ralph plays I  + I  then Felix  can respond with a derivation J ≡ J  + J  . As it  is a winning strategy, this means that Felix will win  both games G(I  , J  ) and G(I  , J  ). By the induction  hypothesis we must have I  ≡ J  and I  ≡ J  , so by  the substitution rule it follows that I ≡ J as required.  ←  −  • I = I . Suppose that for some J , Felix has a winning strategy in the G(I, J ). From this we can deduce  that c(I) = c(J ). Furthermore, we may suppose that  c(I) = (a, b) where b > 0, otherwise we would have  I being equivalent to a shufﬂe operation, and covered  by the case below. Given that c(J ) = (a, b) for b > 0  and Felix has a winning strategy in the game G(I, J )  ←  −  we can see that J must be of the form J  + J  where      c(J ) ≤ c(J ). (If the most complex subexpression of  J was a trail, Ralph would have a winning strategy by  generating an arbitrarily long sequence of I+I  +· · ·+I  ,  and if the most complex subexpression of J was a  shufﬂe, then c(J ) = (a , 0).) In this game Ralph can  force  to match the derivations I ≡ I + I  and J ≡  ←  − Felix    J + (J + J  ). Suppose that Felix does this with the  ←  −  respective derivations J ≡ (J  +K1 )+(K2 +mJ  +J  )  and I ≡ (I + L1 ) + (L2 + kI  ), where m and k are  integers indicating repeated concatenation. As Felix is  applying a winning strategy the following hold (where  A ∼ B indicates Felix has a winning strategy in the  game G(A, B)):  ←  −  ←  −  I ∼ J  + K1  J  ∼ I + L1  I  ∼ K2 + mJ  + J   J  + J  ∼ L2 + kI   I  ∼ L1 + L 2  J  ∼ K1 + K 2  VIII. C ONCLUSION AND F UTURE W ORK  This work presents an important foundation in establishing a  computational model for ﬁrst order theories of linear order. We  have seen that model expressions are expressively complete  for ﬁrst order theories of linear order [9], [3] and the algebra  of Deﬁnition 4 presents a practical resource for reasoning  directly about model expressions. A corollary of Theorem 1 is  that determining equivalence of model-expressions is at most  recursively enumerable. The question of whether this is a lower  bound is left to future work.  R EFERENCES  [1] A. Pnueli, “The temporal logic of programs,” in Proceedings of the  Eighteenth Symposium on Foundations of Computer Science, 1977, pp.  46–57, providence, RI.  [2] T. French, J. C. McCabe-Dansted, and M. Reynolds, “Synthesis for  temporal logic over the reals,” in Advances in Modal Logic, 2012, pp.  217–238.  [3] H. Läuchli and J. Leonard, “On the elementary theory of linear order,”  Fundamenta Mathematicae, vol. 59, pp. 109–116, 1966.  [4] M. Reynolds, “Continuous temporal models,” in Australian Joint Conference on Artiﬁcial Intelligence, ser. Lecture Notes in Computer Science,  M. Stumptner, D. Corbett, and M. J. Brooks, Eds., vol. 2256. Springer,  2001, pp. 414–425.  [5] R. Alur, C. Courcoubetis, N. Halbwachs, T. Henzinger, P.-H. Ho,  X. Nicollin, A. Olivero, J. Sifakis, and S. Yovine, “The algorithmic  analysis of hybrid systems,” Theoretical Computer Science, vol. 138,  no. 1, pp. 3 – 34, 1995.  [6] D. Gabbay, I. Hodkinson, and M. Reynolds, Temporal Logic: Mathematical Foundations and Computational Aspects, Volume 1. Oxford  University Press, 1994.  [7] Y. Gurevich, “Elementary properties of ordered abelian groups,” Algebra  and Logic, vol. 3, pp. 5–39, 1964, (Russian; an English version is in  Trans. Amer. Math. Soc. 46 (1965), 165–192).  [8] J. P. Burgess and Y. Gurevich, “The decision problem for linear temporal  logic,” Notre Dame J. Formal Logic, vol. 26, no. 2, pp. 115–128, 1985.  [9] T. French, J. McCabe-Dansted, and M. Reynolds, “Indiscrete models:  Model building and model checking over linear time,” in Logic and Its  Applications, ser. Lecture Notes in Computer Science, K. Lodaya, Ed.  Springer Berlin Heidelberg, 2013, vol. 7750, pp. 50–68.  [10] E. M. Clarke, O. Grumberg, and D. A. Peled, Model Checking. Cambridge, Massachusetts: The MIT Press, 1999.  From these equations we can infer that K1 ≡ J  (applying the inductive hypothesis). The ﬁrst two identities  recursively reference each other, and by applying the  induction hypothesis and the substitution principle we are  able to derive  xI  ≡ L1 + K1  •  •  and yJ  ≡ K1 + L1  (6)  where x and y are integers indicating repeated concatenation. Then the equivalence I ≡ J follows from the  lead identities (Deﬁnition 4.8-9).  →  −  I = I  . This case is the mirror image of the previous  case and may be treated in a similar way.  I = {I1 , . . . , Im } . For any J such that Felix has a  winning strategy in the game G(I, J ) we may assume  that J is equivalent to some shufﬂe J ≡ {J1 , . . . , Jn } ,  88  78 