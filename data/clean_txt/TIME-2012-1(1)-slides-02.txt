Reasoning about Plan Revision in Agent Programs  Natasha Alechina  University of Nottingham, UK  TIME 2012, Leicester 14 September 2012  Natasha Alechina  Reasoning about plan revision  TIME 2012  1 / 46  What this talk is about  verification (of agent programs with changing plans)  transition systems correspond to agent program execution  model-checking agent programs  joint work with Brian Logan, Mehdi Dastani and John-Jules Meyer  on a theorem-proving approach (using dynamic logic)  main extension: explicit operator for Ã¢Â€Â˜having a planÃ¢Â€Â™  Natasha Alechina  Reasoning about plan revision  TIME 2012  2 / 46  Transition systems  a  c  b  d  p  Natasha Alechina  Reasoning about plan revision  TIME 2012  3 / 46  Dynamic logic  ha; bip, hc; dip  a  c  b  d  p  Natasha Alechina  Reasoning about plan revision  TIME 2012  4 / 46  Having and executing a plan  Plan(a;b)  a  b  p  Natasha Alechina  Reasoning about plan revision  TIME 2012  5 / 46  What is an agent?  many definitions of Ã¢Â€Â˜agentÃ¢Â€Â™ in the literature Ã¢Â€Â” key ideas include:  autonomy: an agent operates without the direct intervention of  humans or other agents  situatedness: an agent interacts with its environment (which may  contain other agents)  reactivity: an agent responds in a timely fashion to changes in its  environment  proactivity: an agent exhibits goal-directed behaviour  Natasha Alechina  Reasoning about plan revision  TIME 2012  6 / 46  What I will mean by an agent  a computational system whose behaviour can be usefully  characterised in terms of propositional attitudes such as beliefs  and goals  and which is programmed in an agent programming language  which makes explicit use of propositional attitudes  Natasha Alechina  Reasoning about plan revision  TIME 2012  7 / 46  What is an agent programming language?  Belief, Desire and Intentions (BDI) framework, (Bratman 1987)  BDI agent programming languages are designed to facilitate the  implementation of BDI agents:  programming constructs corresponding to beliefs, desires and  intentions  agent architecture or interpreter enforces relationships between  beliefs, desires and intentions and which causes the agent to  choose actions to achieve its goals based on its beliefs  Natasha Alechina  Reasoning about plan revision  TIME 2012  8 / 46  3APL  one of the first agent programming languages PRS (Georgeff and  Ingrand 1988), very rich. I will talk about a more modern and less  rich langauge, 3APL  3APL is a BDI agent programming language proposed in (Dastani  et al 2003)  I present a cut-down version of 3APL (mostly regarding the  language for beliefs, but also distinction between external and  internal actions, not considering messages etc.)  Natasha Alechina  Reasoning about plan revision  TIME 2012  9 / 46  3APL beliefs  the beliefs of a 3APL agent represent its information about its  environment and itself  beliefs are represented by a set of positive literals  the initial beliefs of an agent are specified by its program  e.g., the agent may initially believe that itÃ¢Â€Â™s in room1 and its battery  is charged:  Beliefs:  room1, battery  Natasha Alechina  Reasoning about plan revision  TIME 2012  10 / 46  3APL goals  the agentÃ¢Â€Â™s goals represent situations the agent wants to realise  (not necessarily all at once)  goals are represented by a set of arbitrary literals  the initial goals of an agent are specified by its program  e.g., the agent may initially want to achieve a situation in which  both room1 and room2 are clean  Goals:  clean1, clean2  Natasha Alechina  Reasoning about plan revision  TIME 2012  11 / 46  Declarative goals  the beliefs and goals of an agent are related to each other  if an agent believes p, then it will not pursue p as a goal  if an agent does not believe that p, it will not have Ã¢Â€Â“ p as a goal  these relationships are enforced by the agent architecture  Natasha Alechina  Reasoning about plan revision  TIME 2012  12 / 46  3APL basic actions  basic actions specify the capabilities of the agent (what it can do  independent of any particular agent program)  2 types of basic actions:  belief test actions: test whether the agent has a given belief  belief update actions: Ã¢Â€ÂœexternalÃ¢Â€Â actions which change the agentÃ¢Â€Â™s  beliefs  Natasha Alechina  Reasoning about plan revision  TIME 2012  13 / 46  Belief test actions  a belief test action ÄÂ†? tests whether a boolean belief expression ÄÂ†  is entailed by the agentÃ¢Â€Â™s beliefs, e.g. :  (room2 and -battery)?  tests whether the agent believes it is in room2 and its battery is  not charged  Natasha Alechina  Reasoning about plan revision  TIME 2012  14 / 46  Belief update actions  belief update actions change the beliefs (and goals) of the agent  a belief update action is specified in terms of its pre- and  postconditions (sets of literals), e.g. :  {room1} moveR {  }, {-room1, room2}  an action can be executed if one of its pre-conditions is entailed by  the agentÃ¢Â€Â™s current beliefs  executing the action updates the agentÃ¢Â€Â™s beliefs to make one of  the postconditions entailed by the agentÃ¢Â€Â™s beliefs (actions  non-deterministic)  Natasha Alechina  Reasoning about plan revision  TIME 2012  15 / 46  Belief entailment  a belief query (a belief test action or an action precondition) is  entailed by the agentÃ¢Â€Â™s belief base if  all positive literals in the query are contained in the agentÃ¢Â€Â™s belief  base, and  for every negative literal Ã¢Â€Â“ p in the query, p is not in the belief base  i.e., we use entailment under the closed world assumption  goal entailment corresponds to a formula being classically  entailed by one of the goals in the goal base  Natasha Alechina  Reasoning about plan revision  TIME 2012  16 / 46  Belief update  executing a belief update action  adds all positive literals in the corresponding postcondition to the  belief base, and  for every negative literal Ã¢Â€Â“ p in the postcondition, p is removed from  the agentÃ¢Â€Â™s belief base  goals which are achieved by the postcondition of an action are  dropped  for simplicity, we assume that the agentÃ¢Â€Â™s beliefs about its  environment are always correct and its actions in the environment  are always successful  Natasha Alechina  Reasoning about plan revision  TIME 2012  17 / 46  Abstract plans  unlike basic actions, abstract plans cannot be directly executed by  the agent.  abstract plans provide an abstraction mechanism (similar to  procedures in imperative programming) which are expanded into  basic actions using plan revision rules  if the first step of a plan ÄÂ€ is an abstract plan ÃÄ…ÄšÂ„, execution of ÄÂ€  blocks.  Natasha Alechina  Reasoning about plan revision  TIME 2012  18 / 46  3APL plans  plans are sequences of basic actions and atomic plans composed  by plan composition operators:  sequence: Ã¢Â€ÂœÄÂ€1 ;ÄÂ€2 Ã¢Â€Â (do ÄÂ€1 then ÄÂ€2 )  conditional choice: Ã¢Â€Âœif ÄÂ† then {ÄÂ€1 } else {ÄÂ€2 }Ã¢Â€Â  conditional iteration: Ã¢Â€Âœwhile ÄÂ† do {ÄÂ€}Ã¢Â€Â  e.g., the plan:  if room1 then {suck} else {moveL; suck}  causes the agent to clean room1 if itÃ¢Â€Â™s currently in room1,  otherwise it first moves (left) to room1 and then cleans it  Natasha Alechina  Reasoning about plan revision  TIME 2012  19 / 46  3APL PG rules  planning goal rules are used for plan selection based on the  agentÃ¢Â€Â™s current goals and beliefs  a planning goal rule ÃÅŸ Ã¢Â†Â ÃË› | ÄÂ€ consists of three parts:  ÃÅŸ: an (optional) goal query which specifies which goal(s) the plan  achieves  ÃË›: a belief query which characterises the situation(s) in which it  could be a good idea to execute the plan  ÄÂ€: a plan  a PG rule can be applied if ÃÅŸ is entailed by the agentÃ¢Â€Â™s goals and ÃË›  is entailed by the agentÃ¢Â€Â™s beliefs  applying the rule adds ÄÂ€ to the agentÃ¢Â€Â™s plans  Natasha Alechina  Reasoning about plan revision  TIME 2012  20 / 46  Example 3APL PG rules  clean2 <- battery |  if room2 then {suck} else {moveR; suck}  states that Ã¢Â€Âœif the agentÃ¢Â€Â™s goal is to clean room2 and its battery is  charged, then the specified plan may be used to clean the roomÃ¢Â€Â  an agent can generate a plan based only on its current beliefs  (reactive invocation), e.g., the rule:  <- -battery |  if room2 then {charge} else {moveR; charge}  states Ã¢Â€Âœif the battery is low, the specified plan may be used to  charge itÃ¢Â€Â  Natasha Alechina  Reasoning about plan revision  TIME 2012  21 / 46  Example 3APL PR rules  a plan revision rule pj = ÄÂ€j Ã¢Â†Â ÃË›j | ÄÂ€ 0 j can be applied if ÄÂ€j is in the  plan base, ÃË›j is entailed by the agentÃ¢Â€Â™s beliefs and ÄÂ€j is not  executable,  in other words the first action of ÄÂ€j is either a belief update or  belief test action which is not executable in the current belief state,  or an abstract plan  for example, if moveR fails, the agent may execute a slow but  reliable version of the action, slowR:  charge <- room1 |  {slowR; charge}  Natasha Alechina  Reasoning about plan revision  TIME 2012  22 / 46  Operational semantics  we define the operational semantics of 3APL in terms of a  transition system  states are agent configurations hÄÂƒ, ÃÅ‚, ÃÂ i where ÄÂƒ, ÃÅ‚ are sets of  literals representing the agentÃ¢Â€Â™s beliefs and goals, and ÃÂ  is a set of  plan entries representing the agentÃ¢Â€Â™s current active plans  (annotated by the goals which they were adopted to achieve)  each transition corresponds to a single step in the execution of the  agent  different execution strategies give rise to different semantics  for simplicity we focus on non-interleaved executionÃ¢Â€Â”i.e., the  agent executes a single plan to completion before choosing  another plan  Natasha Alechina  Reasoning about plan revision  TIME 2012  23 / 46  Formal entailment definitions  |=cwa (belief entailment for closed world assumption):  ÄÂƒ |=cwa p iff p Ã¢ÂˆÂˆ ÄÂƒ  ÄÂƒ |=cwa Ã¢ÂˆÂ’p iff p 6Ã¢ÂˆÂˆ ÄÂƒ  ÄÂƒ |=cwa ÄÂ† and ÄÂˆ iff ÄÂƒ |=cwa ÄÂ† and ÄÂƒ |=cwa ÄÂˆ  ÄÂƒ |=cwa ÄÂ† or ÄÂˆ iff ÄÂƒ |=cwa ÄÂ† or ÄÂƒ |=cwa ÄÂˆ  ÄÂƒ |=cwa {ÄÂ†1 , . . . , ÄÂ†n } iff Ã¢ÂˆÂ€1 Ã¢Â‰Â¤ i Ã¢Â‰Â¤ n ÄÂƒ |=cwa ÄÂ†i  |=g (goal entailment):  ÃÅ‚ |=g p iff p Ã¢ÂˆÂˆ ÃÅ‚  ÃÅ‚ |=g Ã¢ÂˆÂ’p iff Ã¢ÂˆÂ’p Ã¢ÂˆÂˆ ÃÅ‚  ÃÅ‚ |=g ÄÂ† or ÄÂˆ iff ÃÅ‚ |=g ÄÂ† or ÃÅ‚ |=g ÄÂˆ  Natasha Alechina  Reasoning about plan revision  TIME 2012  24 / 46  Belief update function  let a be a belief update action and ÄÂƒ a belief base such that  ÄÂƒ |=cwa precj (a)  intuitively, ÄÂƒ |=cwa precj (a) if it contains all positive literals in  precj (a) and does not contain the negative ones  the result of executing belief update action a with respect to ÄÂƒ  (assuming precj (a) holds and the action results in the postj,i  becoming true) is defined as:  Tj,i (a, ÄÂƒ) = (ÄÂƒ Ã¢ÂˆÅ {p : p Ã¢ÂˆÂˆ postj,i (a)}) \ {p : Ã¢Â€Â“ p Ã¢ÂˆÂˆ postj,i (a)}  intuitively, the result of the update satisfies (entails under |=cwa )  the corresponding postcondition postj,i (a)  Natasha Alechina  Reasoning about plan revision  TIME 2012  25 / 46  Transitions: belief test actions  belief test actions  ÄÂƒ |=cwa ÃË›  hÄÂƒ, ÃÅ‚, {ÃË›? ; ÄÂ€ . ÃÅŸ}i Ã¢ÂˆÂ’Ã¢Â†Â’ hÄÂƒ, ÃÅ‚, {ÄÂ€ . ÃÅŸ}i  Natasha Alechina  Reasoning about plan revision  TIME 2012  26 / 46  Transitions: belief update actions  belief update actions when the corresponding goal not achieved  yet:  ÄÂƒ |=cwa preci (ÃÄ…) Ti,j (ÃÄ…, ÄÂƒ) = ÄÂƒ 0 ÃÅ‚ 0 = ÃÅ‚ \ {ÄÂ† | ÄÂƒ 0 |=cwa ÄÂ†} ÄÂƒ 0 6|=cwa ÃÅŸ  hÄÂƒ, ÃÅ‚, {ÃÄ…; ÄÂ€ . ÃÅŸ}i Ã¢ÂˆÂ’Ã¢Â†Â’ hÄÂƒ 0 , ÃÅ‚ 0 , {ÄÂ€ . ÃÅŸ}i  belief update actions when the corresponding goal is achieved:  ÄÂƒ |=cwa preci (ÃÄ…) Ti,j (ÃÄ…, ÄÂƒ) = ÄÂƒ 0 ÃÅ‚ 0 = ÃÅ‚ \ {ÄÂ† | ÄÂƒ 0 |=cwa ÄÂ†} ÄÂƒ 0 |=cwa ÃÅŸ  hÄÂƒ, ÃÅ‚, {ÃÄ…; ÄÂ€ . ÃÅŸ}i Ã¢ÂˆÂ’Ã¢Â†Â’ hÄÂƒ 0 , ÃÅ‚ 0 , { }i  Natasha Alechina  Reasoning about plan revision  TIME 2012  27 / 46  Transitions: plans  conditional choice  ÄÂƒ |=cwa ÄÂ†  hÄÂƒ, ÃÅ‚, {(if ÄÂ† then ÄÂ€1 else ÄÂ€2 ); ÄÂ€ . ÃÅŸ}i Ã¢ÂˆÂ’Ã¢Â†Â’ hÄÂƒ, ÃÅ‚, {ÄÂ€1 ; ÄÂ€ . ÃÅŸ}i  ÄÂƒ 6|=cwa ÄÂ†  hÄÂƒ, ÃÅ‚, {(if ÄÂ† then ÄÂ€1 else ÄÂ€2 ); ÄÂ€ . ÃÅŸ}i Ã¢ÂˆÂ’Ã¢Â†Â’ hÄÂƒ, ÃÅ‚, {ÄÂ€2 ; ÄÂ€ . ÃÅŸ}i  conditional iteration  ÄÂƒ |=cwa ÄÂ†  hÄÂƒ, ÃÅ‚, {(while ÄÂ† do ÄÂ€1 ); ÄÂ€ . ÃÅŸ}i Ã¢ÂˆÂ’Ã¢Â†Â’ hÄÂƒ, ÃÅ‚, {ÄÂ€1 ; (while ÄÂ† do ÄÂ€1 ); ÄÂ€ . ÃÅŸ  ÄÂƒ 6|=cwa ÄÂ†  hÄÂƒ, ÃÅ‚, {(while ÄÂ† do ÄÂ€1 . ÃÅŸ); ÄÂ€}i Ã¢ÂˆÂ’Ã¢Â†Â’ hÄÂƒ, ÃÅ‚, {ÄÂ€ . ÃÅŸ}i  Natasha Alechina  Reasoning about plan revision  TIME 2012  28 / 46  Transitions: PG rules  planning goal rules ÃÅŸ Ã¢Â†Â ÃË› | ÄÂ€  ÃÅ‚ |=g ÃÅŸ ÄÂƒcwa |= ÃË›  hÄÂƒ, ÃÅ‚, {}i Ã¢ÂˆÂ’Ã¢Â†Â’ hÄÂƒ, ÃÅ‚, {ÄÂ€ . ÃÅŸ}i  Natasha Alechina  Reasoning about plan revision  TIME 2012  29 / 46  Transitions: PR rules  plan revision rules pj = ÄÂ€j Ã¢Â†Â ÃË›j | ÄÂ€ 0 j  Ã¢ÂˆÂ€i ÄÂƒ 6|=cwa preci (ÃÄ…) ÄÂƒ |=cwa ÃË›j  hÄÂƒ, ÃÅ‚, {ÄÂ€j = ÃÄ…; ÄÂ€ . ÃÅŸ}i Ã¢ÂˆÂ’Ã¢Â†Â’ hÄÂƒ, ÃÅ‚, {ÄÂ€ 0 j . ÃÅŸ}i  ÄÂƒ 6|=cwa ÃË›  ÄÂƒ |=cwa ÃË›j  hÄÂƒ, ÃÅ‚, {ÄÂ€j = ÃË›? ; ÄÂ€ . ÃÅŸ}i Ã¢ÂˆÂ’Ã¢Â†Â’ hÄÂƒ, ÃÅ‚, {ÄÂ€ 0 j . ÃÅŸ}i  ÄÂƒ |=cwa ÃË›j  hÄÂƒ, ÃÅ‚, {ÄÂ€j = ÃÄ…ÄšÂ„; ÄÂ€ . ÃÅŸ}i Ã¢ÂˆÂ’Ã¢Â†Â’ hÄÂƒ, ÃÅ‚, {ÄÂ€ 0 j ; ÄÂ€ . ÃÅŸ}i  where ÃÄ…ÄšÂ„ is the name of an abstract plan.  Natasha Alechina  Reasoning about plan revision  TIME 2012  30 / 46  State of the art  State of the art in model-checking agent programs  Model-checking AgentSpeak (Promela, Spin)  Rafael H. Bordini, Michael Fisher, Carmen Pardavila, Michael  Wooldridge: Model checking AgentSpeak. AAMAS 2003:409-416  General platform for model-checking BDI agents (AIL and AJPF)  Louise A. Dennis, Michael Fisher, Matthew P. Webster, Rafael H.  Bordini: Model checking agent programming languages. Autom.  Softw. Eng. 19(1): 5-63 (2012)  Work with Goal, 3/2APL,...  Natasha Alechina  Reasoning about plan revision  TIME 2012  31 / 46  State of the art  Challenges  In common with general model-checking: scalability issues  In common with general (software) model-checking: hard to deal  with an infinite number of possible inputs/events, first-order  properties  I think there is still no system specification language at the right  level of abstraction  Beliefs, goals, plans, etc. are treated as just ordinary data  structures: same as lists of strings or some other Ã¢Â€Â˜dumbÃ¢Â€Â™ values  However, they do have some logical structure (e.g. closure under  the agentÃ¢Â€Â™s reasoning rules) and connections to each other, which  should be used, in a transparent fashion (use something more like  Maude?)  The most interesting logical challenge here I think is the logic of  having committed to a set of intentions  Natasha Alechina  Reasoning about plan revision  TIME 2012  32 / 46  State of the art  What does having a set of intentions mean  If an agentÃ¢Â€Â™s set of intentions is {a; b; c, d; e; f } then it is easy to  figure out what the possible actions by the agent are (a and d); for  more general plans it is more complicated, but also well defined  no logic with explicit adopted plans (in the logical language), apart  from TCS11 (for single agent/single plan) and a paper in informal  proceedings of DALT 2009.  there are logics with explicit strategies (Simon and Ramanujam  2008,2009), but strategies and plans are not exactly the same and  logics have no Ã¢Â€Â˜he has adopted this strategyÃ¢Â€Â™ operator  Natasha Alechina  Reasoning about plan revision  TIME 2012  33 / 46  State of the art  Verification by theorem proving  State properties of the system as axioms (completely axiomatise  the operational semantics)  Prove that the desired property logically follows from them  This is a more complex problem than model-checking, but it is  easier to deal with first-order, infinite domains, etc.  Natasha Alechina  Reasoning about plan revision  TIME 2012  34 / 46  Logic  Signature of an agent program  The signature of an agent program R is defined as R = hP, PG,  Ã‚Å» Act, Plani  PR, Ac, Ac,  P is a set of belief and goal atoms  PG is a set of planning goal rules, ri = ÃÅŸi Ã¢Â†Â ÃË›i | ÄÂ€i  PR is a set of plan revision rules, pj = ÄÂ€j Ã¢Â†Â ÃË›j | ÄÂ€j0  Ac is a set of belief update actions occurring in the plans of PG and  PR rules  Ã‚Å» is a set of abstract plans occurring in the plans of PG and PR  Ac  rules  Act is the set of specifications for belief update actions Ac  Plan is the set of all possible ÄÂ€ . ÃÅŸ pairs where ÃÅŸ is one of the  agentÃ¢Â€Â™s goals and ÄÂ€ is a plan occurring in PG and PR rules or a  suffix of such a plan  Natasha Alechina  Reasoning about plan revision  TIME 2012  35 / 46  Logic  Language of PDL-3APL  program expressions:  Ã‚Å» | ÃÂ´r i | ÃÂ´p | ÄÂ1 ; ÄÂ2 | ÄÂ1 Ã¢ÂˆÅ ÄÂ2 | ÄÂÃ¢ÂˆÂ—  ÄÂ ::= ÃÄ… Ã¢ÂˆÂˆ Ac | t(ÄÂ†) | aÄšÂ„ Ã¢ÂˆÂˆ Ac  j  formula:  ÄÂˆ ::= Bp | Gp | G Ã¢Â€Â“ p | x | P ÃÅŸ ÄÂ€ | P |Ã‚Å¹ÄÂˆ | ÄÂˆ1 Ã¢ÂˆÂ§ ÄÂˆ2 | hÄÂiÄÂˆ  Natasha Alechina  Reasoning about plan revision  TIME 2012  36 / 46  Logic  Models of PDL-3APL  Ã‚Å» Act, Plani be the signature of an agent  Let R = hP, PG, PR, Ac, Ac,  program. A PDL-3APL model M relative to R is defined as  M = (W , V , RÃÄ… , Rt(ÄÂ†) , RÃÄ…ÄšÂ„ , RÃÂ´r i , RÃÂ´p j )  where  W is a non-empty set of states.  V = (Vb , Vg , Vc , Vp ) such that for every s Ã¢ÂˆÂˆ W :  Vb (s) = {p1 , . . . , pm : pi Ã¢ÂˆÂˆ P} is the set of the agentÃ¢Â€Â™s beliefs in s;  Vg (s) = {( Ã¢Â€Â“ )u1 , . . . , ( Ã¢Â€Â“ )un : ui Ã¢ÂˆÂˆ P} is the set of the agentÃ¢Â€Â™s goals  in s (note that Vg assigns literals rather than propositional  variables);  Vc (s) is either an empty set or {x};  Vp (s) is either the empty set or a singleton set {ÄÂ€ . ÃÅŸ}, where ÄÂ€ is  the agentÃ¢Â€Â™s plan in s and ÃÅŸ is the goal(s) achieved by this plan  RÃÄ… , Rt(ÄÂ†) , RÃÄ…ÄšÂ„ , RÃÂ´r i , RÃÂ´p i are binary relations on W  Natasha Alechina  Reasoning about plan revision  TIME 2012  37 / 46  Logic  Conditions on models  C1 Vg (s) Ã¢ÂˆÅ  Vb (s) = Ã¢ÂˆÂ… and {p : Ã¢Â€Â“ p Ã¢ÂˆÂˆ Vg (s)} Ã¢ÂŠÂ† Vb (s)  C2 If Vp (s) = {ÃÄ…; ÄÂ€ . ÃÅŸ}, Vb (s) |=cwa preci (ÃÄ…) and x 6Ã¢ÂˆÂˆ Vc (s), then  there is an RÃÄ… transition to a state s0 where Vb (s0 ) = Ti,j (ÃÄ…, Vb (s)),  Vg (s0 ) = Vg (s) \ ({p : p Ã¢ÂˆÂˆ Vb (s0 )} Ã¢ÂˆÅ { Ã¢Â€Â“ p : p 6Ã¢ÂˆÂˆ Vb (s0 )}) and if  Vb (s0 ) 6|=cwa ÃÅŸ, Vp (s0 ) = {ÄÂ€ . ÃÅŸ}.  If Vb (s0 ) |=cwa ÃÅŸ, x Ã¢ÂˆÂˆ Vc (s0 ) and Vp (s0 ) = {}.  C3Ã¢Â€Â“C10 similarly correspond to operational semantics in non-x  states  Natasha Alechina  Reasoning about plan revision  TIME 2012  38 / 46  Logic  Conditions for exceptional states  Condition for non-executable actions: if Vp (s) = {ÃÄ…; ÄÂ€ . ÃÅŸ},  Vb (s) 6|=cwa preci (ÃÄ…), and x 6Ã¢ÂˆÂˆ Vc (s), then there is an RÃÄ…  transition to a state s0 where x Ã¢ÂˆÂˆ Vc (s0 ).  Condition for executing in exceptional states: if x Ã¢ÂˆÂˆ Vc (s) then  there are RÃÄ… , RÃÄ…ÄšÂ„ and Rt(ÄÂ†) transitions from state s to itself  Condition for PR rules: if x Ã¢ÂˆÂˆ Vc (s), Vp (s) = {ÄÂ€j . ÃÅŸ},  Vb (s) |=cwa ÃË›j , then there is a RÃÂ´p j transition to a state s0 where  Vp (s0 ) = {ÄÂ€j0 . ÃÅŸ} and x 6Ã¢ÂˆÂˆ Vc (s0 ) (where pj = ÄÂ€j Ã¢Â†Â ÃË›j | ÄÂ€j0 ).  Natasha Alechina  Reasoning about plan revision  TIME 2012  39 / 46  Logic  Satisfaction  M, s |= Bp iff p Ã¢ÂˆÂˆ Vb (s)  M, s |= Gp iff p Ã¢ÂˆÂˆ Vg (s)  M, s |= G Ã¢Â€Â“ p iff Ã¢Â€Â“ p Ã¢ÂˆÂˆ Vg (s)  M, s |= x iff x Ã¢ÂˆÂˆ Vc (s)  M, s |= P ÃÅŸ ÄÂ€ iff Vp (s) = {ÄÂ€ . ÃÅŸ}  M, s |= P iff Vp (s) = {}  M, s |= Ã‚Å¹ÄÂˆ iff M, s 6|= ÄÂˆ  M, s |= ÄÂˆ1 Ã¢ÂˆÂ§ ÄÂˆ2 iff M, s |= ÄÂˆ1 and M, s |= ÄÂˆ2  M, s |= hÄÂiÄÂˆ iff there exists s0 such that RÄÂ (s, s0 ) and M, s0 |= ÄÂˆ.  Natasha Alechina  Reasoning about plan revision  TIME 2012  40 / 46  Logic  Translation into PDL  fb : fb (p) = Bp; fb (ÄÂ† and ÄÂˆ) = fb (ÄÂ†) Ã¢ÂˆÂ§ fb (ÄÂˆ);  fb (ÄÂ† or ÄÂˆ) = fb (ÄÂ†) Ã¢ÂˆÂ¨ fb (ÄÂˆ)  fg (p) = Gp; fg ( Ã¢Â€Â“ p) = G Ã¢Â€Â“ p  fp :  fp (ÃÄ…) = ÃÄ…  fp (ÄÂ†?) = t(ÄÂ†)  fp (ÃÄ…ÄšÂ„) = ÃÄ…ÄšÂ„  fp (ÄÂ€1 ; ÄÂ€2 ) = fp (ÄÂ€1 ); fp (ÄÂ€2 )  fp (if ÄÂ† then ÄÂ€1 else ÄÂ€2 ) = t(ÄÂ†); fp (ÄÂ€1 )) Ã¢ÂˆÅ (t(Ã‚Å¹ÄÂ†); fp (ÄÂ€2 ))  fp (while ÄÂ† do ÄÂ€) = (t(ÄÂ†); fp (ÄÂ€))Ã¢ÂˆÂ— ; t(Ã‚Å¹ÄÂ†).  Natasha Alechina  Reasoning about plan revision  TIME 2012  41 / 46  Logic  Axioms  A1 Bp Ã¢Â†Â’ Ã‚Å¹Gp  A2 G Ã¢Â€Â“ p Ã¢Â†Â’ Bp  0  A3a P ÃÅŸ ÄÂ€ Ã¢Â†Â’ Ã‚Å¹P ÃÅŸ ÄÂ€ 0 where ÄÂ€ 0 6= ÄÂ€ or ÃÅŸ0 6= ÃÅŸ  W  A3b P Ã¢ÂˆÂ¨ ÄÂ€.ÃÅŸÃ¢ÂˆÂˆPlan P ÃÅŸ ÄÂ€  BA1 Ã‚Å¹x Ã¢ÂˆÂ§ P ÃÅŸ (ÃÄ…; ÄÂ€) Ã¢ÂˆÂ§ fb (preci (ÃÄ…)) Ã¢ÂˆÂ§ ÄÂˆ Ã¢ÂˆÂ§ ÄÂˆ 0 Ã¢Â†Â’ hÃÄ…i(  (fb (postij (ÃÄ…))Ã¢ÂˆÂ§Ã‚Å¹fb (ÃÅŸ)Ã¢ÂˆÂ§P ÃÅŸ ÄÂ€Ã¢ÂˆÂ§ÄÂˆ)Ã¢ÂˆÂ¨(fb (postij (ÃÄ…))Ã¢ÂˆÂ§fb (ÃÅŸ)Ã¢ÂˆÂ§x Ã¢ÂˆÂ§PÃ¢ÂˆÂ§ÄÂˆ 0 ))  where ÄÂˆ, ÄÂˆ 0 are any formulas not containing plan expressions or  literals in fb (postij (ÃÄ…)), and in addition ÄÂˆ 0 does not contain x  Ã‚Å»  BA2a Ã‚Å¹x Ã¢ÂˆÂ§ P ÃÅŸ ÄÂ€ Ã¢Â†Â’ [u]Ã¢ÂŠÄ½ where ÄÂ€ 6= u; ÄÂ€ 0 and u Ã¢ÂˆÂˆ Ac Ã¢ÂˆÅ Ac  BA2b Ã‚Å¹x Ã¢ÂˆÂ§ P ÃÅŸ ÄÂ€ Ã¢Â†Â’ [t(ÄÂ†)]Ã¢ÂŠÄ½ if ÄÂ€ does not start with a belief test action ÄÂ†?  or a conditional plan test on ÄÂˆ where ÄÂ† = ÄÂˆ or ÄÂ† = Ã‚Å¹ÄÂˆ  Natasha Alechina  Reasoning about plan revision  TIME 2012  42 / 46  Logic  Axioms continued  V  V 0  ÃÅŸ (ÃÄ…; ÄÂ€) Ã¢ÂˆÂ§ f (prec (ÃÄ…)) Ã¢ÂˆÂ§  BA3 Ã‚Å¹x  Ã¢ÂˆÂ§  P  ÄÂˆ  Ã¢ÂˆÂ§  b  j  i  j  j ÄÂˆj Ã¢Â†Â’ [ÃÄ…](  W  ÃÅŸ  Wj ( fb (postij (ÃÄ…)) Ã¢ÂˆÂ§ Ã‚Å¹fb (ÃÅŸ) Ã¢ÂˆÂ§ P ÄÂ€ Ã¢ÂˆÂ§ ÄÂˆj )0 Ã¢ÂˆÂ¨  j ( fb (postij (ÃÄ…)) Ã¢ÂˆÂ§ fb (ÃÅŸ) Ã¢ÂˆÂ§ x Ã¢ÂˆÂ§ P Ã¢ÂˆÂ§ ÄÂˆj ))  where ÄÂˆj and ÄÂˆj0 are any formulas not containing plan expressions  or literals in fb (postij (ÃÄ…)), and in addition ÄÂˆj0 does not contain x  BA4 Ã‚Å¹x Ã¢ÂˆÂ§ P ÃÅŸ (ÄÂ†? ; ÄÂ€) Ã¢ÂˆÂ§ fb (ÄÂ†) Ã¢ÂˆÂ§ ÄÂˆnp Ã¢Â†Â’ h[t(ÄÂ†)]i(P ÃÅŸ ÄÂ€ Ã¢ÂˆÂ§ ÄÂˆnp )  V  BA5 Ã‚Å¹x Ã¢ÂˆÂ§ P ÃÅŸ (ÃÄ…; ÄÂ€) Ã¢ÂˆÂ§ i Ã‚Å¹fb (preci (ÃÄ…)) Ã¢ÂˆÂ§ ÄÂˆnx Ã¢Â†Â’ h[ÃÄ…]i(x Ã¢ÂˆÂ§ ÄÂˆnx )  BA6 Ã‚Å¹x Ã¢ÂˆÂ§ P ÃÅŸ (ÄÂ†? ; ÄÂ€) Ã¢ÂˆÂ§ Ã‚Å¹fb (ÄÂ†) Ã¢ÂˆÂ§ ÄÂˆnx Ã¢Â†Â’ h[t(ÄÂ†)]i(x Ã¢ÂˆÂ§ ÄÂˆnx )  BA7 Ã‚Å¹x Ã¢ÂˆÂ§ P ÃÅŸ (ÃÄ…ÄšÂ„; ÄÂ€) Ã¢ÂˆÂ§ ÄÂˆnx Ã¢Â†Â’ h[ÃÄ…ÄšÂ„]i(x Ã¢ÂˆÂ§ ÄÂˆnx )  BA8 x Ã¢ÂˆÂ§ ÄÂˆ Ã¢Â†Â’ h[u]iÄÂˆ where u is ÃÄ…, t(ÄÂ†) or ÃÄ…ÄšÂ„  Natasha Alechina  Reasoning about plan revision  TIME 2012  43 / 46  Logic  Axioms continued  CP1 Ã‚Å¹x Ã¢ÂˆÂ§ P ÃÅŸ (ÄÂ€if ; ÄÂ€) Ã¢ÂˆÂ§ fb (ÄÂ†) Ã¢ÂˆÂ§ ÄÂˆnp Ã¢Â†Â’ h[t(ÄÂ†)]i(P ÃÅŸ ÄÂ€1 ; ÄÂ€ Ã¢ÂˆÂ§ ÄÂˆnp ), where ÄÂ€if is  of the form if ÄÂ† then ÄÂ€1 else ÄÂ€2  CP2 Ã‚Å¹x Ã¢ÂˆÂ§ P ÃÅŸ (ÄÂ€if ; ÄÂ€) Ã¢ÂˆÂ§ Ã‚Å¹fb (ÄÂ†) Ã¢ÂˆÂ§ ÄÂˆnp Ã¢Â†Â’ h[t(Ã‚Å¹ÄÂ†)]i(P ÃÅŸ ÄÂ€2 ; ÄÂ€ Ã¢ÂˆÂ§ ÄÂˆnp ), where  ÄÂ€if is as in CP1  CP3 Ã‚Å¹x Ã¢ÂˆÂ§ P ÃÅŸ (ÄÂ€wh ; ÄÂ€) Ã¢ÂˆÂ§ fb (ÄÂ†) Ã¢ÂˆÂ§ ÄÂˆnp Ã¢Â†Â’ h[t(ÄÂ†)]i(P ÃÅŸ ÄÂ€1 ; ÄÂ€wh ; ÄÂ€ Ã¢ÂˆÂ§ ÄÂˆnp ), where  ÄÂ€wh is of the form while ÄÂ† do ÄÂ€1  CP4 Ã‚Å¹x Ã¢ÂˆÂ§ P ÃÅŸ (ÄÂ€wh ; ÄÂ€) Ã¢ÂˆÂ§ Ã‚Å¹fb (ÄÂ†) Ã¢ÂˆÂ§ ÄÂˆnp Ã¢Â†Â’ h[t(Ã‚Å¹ÄÂ†)]i(P ÃÅŸ ÄÂ€ Ã¢ÂˆÂ§ ÄÂˆnp ), where ÄÂ€wh  is as in CP3  CP5 Ã‚Å¹x Ã¢ÂˆÂ§ (P ÃÅŸ ÄÂ€if Ã¢ÂˆÂ¨ P ÃÅŸ ÄÂ€wh ) Ã¢ÂˆÂ§ Ã‚Å¹fb (ÄÂ†) Ã¢Â†Â’ [t(ÄÂ†)]Ã¢ÂŠÄ½ where ÄÂ€if and ÄÂ€wh are as  above  PG1 P Ã¢ÂˆÂ§ fg (ÃÅŸi ) Ã¢ÂˆÂ§ fb (ÃË›i ) Ã¢ÂˆÂ§ ÄÂˆnpx Ã¢Â†Â’ h[ÃÂ´r i ]i(Ã‚Å¹x Ã¢ÂˆÂ§ P ÃÅŸi ÄÂ€i Ã¢ÂˆÂ§ ÄÂˆnpx )  PG2 Ã‚Å¹P Ã¢ÂˆÂ¨ Ã‚Å¹fg (ÃÅŸi ) Ã¢ÂˆÂ¨ Ã‚Å¹fb (ÃË›i ) Ã¢Â†Â’ [ÃÂ´r i ]Ã¢ÂŠÄ½  PR1 x Ã¢ÂˆÂ§ P ÃÅŸ ÄÂ€j Ã¢ÂˆÂ§ fb (ÃË›j ) Ã¢ÂˆÂ§ ÄÂˆnpx Ã¢Â†Â’ h[ÃÂ´p j ]i(Ã‚Å¹x Ã¢ÂˆÂ§ P ÃÅŸ ÄÂ€j0 Ã¢ÂˆÂ§ ÄÂˆnpx )  PR2 Ã‚Å¹x Ã¢ÂˆÂ¨ Ã‚Å¹P ÃÅŸ ÄÂ€j Ã¢ÂˆÂ¨ Ã‚Å¹fb (ÃË›j ) Ã¢Â†Â’ [ÃÂ´p j ]Ã¢ÂŠÄ½  Natasha Alechina  Reasoning about plan revision  TIME 2012  44 / 46  Logic  Translation of the program  tr (R) = (Ã¢ÂˆÅi (ÃÂ´r i ; fp (ÄÂ€i ))  S  Ã¢ÂˆÅj (ÃÂ´p j ; fp (ÄÂ€j0 )))+  Theorem: tr (R) picks out exactly those paths in a model which  correspond to an execution of the program  Can verify liveness and safety properties by checking whether  htr (R)iÄÂ† and [tr (R)]ÄÂ† are entailed by the formulas describing initial  conditions  complications: encoding plan expressions; encoding properties  which hold along a path (Fahad Khan 2012, Regular Path  Temporal Logic)  Natasha Alechina  Reasoning about plan revision  TIME 2012  45 / 46  Logic  Conclusions  agent programs can be verified just as ordinary programs  however they have additional properties which it may be possible  to expoit  one of the properties is having an explicit set of plans, which  seems to be an interesting logical property  may be also of interest for game logics (being able to say Ã¢Â€Â˜this  player is going to play this strategyÃ¢Â€Â™ rather than Ã¢Â€Â˜if this player plays  this strategyÃ¢Â€Â™)  Natasha Alechina  Reasoning about plan revision  TIME 2012  46 / 46 